{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.3.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (2.8.8)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading tbb-2021.13.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.3.1-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Downloading tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.9/286.9 kB 5.9 MB/s eta 0:00:00\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 177.6/177.6 kB 11.2 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading sympy-1.13.0-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.5/6.2 MB 46.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 43.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 39.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 43.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 35.9 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, mkl, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 intel-openmp-2021.4.0 jinja2-3.1.4 mkl-2021.4.0 mpmath-1.3.0 sympy-1.13.0 tbb-2021.13.0 torch-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (2.3.1)\n",
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "     ---------------------------------------- 0.0/210.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 210.0/210.0 kB 4.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-cluster\n",
      "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
      "     ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 54.5/54.5 kB 2.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-spline-conv\n",
      "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
      "     ---------------------------------------- 0.0/64.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 64.2/64.2 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch-sparse) (1.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch-geometric) (4.66.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Collecting aiohttp (from torch-geometric)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
      "Collecting scikit-learn (from torch-geometric)\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from torch-geometric) (6.0.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch-geometric)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->torch-geometric)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from requests->torch-geometric) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from requests->torch-geometric) (2024.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->torch-geometric)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   -------------------------------------- - 1.1/1.1 MB 33.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 23.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "   ---------------------------------------- 0.0/369.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 369.0/369.0 kB 22.4 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "   ---------------------------------------- 0.0/10.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.9/10.9 MB 42.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.2/10.9 MB 45.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.2/10.9 MB 44.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/10.9 MB 42.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/10.9 MB 40.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/10.9 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/10.9 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/10.9 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.9/10.9 MB 26.2 MB/s eta 0:00:00\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Building wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-win_amd64.whl size=351975 sha256=05206cbb20417f20228b047064282459acb5eb24c95eaeb8ddcf9ed4a95ea41b\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\84\\20\\50\\44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
      "  Building wheel for torch-sparse (setup.py): started\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): still running...\n",
      "  Building wheel for torch-sparse (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-win_amd64.whl size=754569 sha256=3b377505000324b52b9cd96bd8baf9c3ac564a8a0bf9ed4276133d73a729dcf3\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\71\\fa\\21\\bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
      "  Building wheel for torch-cluster (setup.py): started\n",
      "  Building wheel for torch-cluster (setup.py): still running...\n",
      "  Building wheel for torch-cluster (setup.py): still running...\n",
      "  Building wheel for torch-cluster (setup.py): still running...\n",
      "  Building wheel for torch-cluster (setup.py): still running...\n",
      "  Building wheel for torch-cluster (setup.py): still running...\n",
      "  Building wheel for torch-cluster (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp312-cp312-win_amd64.whl size=515863 sha256=c21033f29957c8dce8fde014b7068c54213e1d9e7389b3e6bc43a7142818c5b1\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\2e\\8f\\d0\\13408a84825c9a587151a74727b4a6d47ec67e0d625b385ad7\n",
      "  Building wheel for torch-spline-conv (setup.py): started\n",
      "  Building wheel for torch-spline-conv (setup.py): still running...\n",
      "  Building wheel for torch-spline-conv (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.2-cp312-cp312-win_amd64.whl size=184541 sha256=a829548dd5d820f3f4cd00b9899a3ad27a3bd91fceb5411f2eab07e823dd063c\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\54\\7a\\2e\\46a729dc0aad2da1a908b0d2ac86ab127d73e6b4310a945d07\n",
      "Successfully built torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
      "Installing collected packages: torch-spline-conv, torch-scatter, threadpoolctl, multidict, frozenlist, attrs, yarl, torch-sparse, torch-cluster, scikit-learn, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 frozenlist-1.4.1 multidict-6.0.5 scikit-learn-1.5.1 threadpoolctl-3.5.0 torch-cluster-1.6.3 torch-geometric-2.5.3 torch-scatter-2.1.2 torch-sparse-0.6.18 torch-spline-conv-1.2.2 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (16.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (2.8.8)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\onedrive\\documents\\eduardo toledo\\asai\\graph_customer_segmentation\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn matplotlib pandas pyarrow networkx matplotlib  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. OVERVIEW \n",
    "## Graph Construction:\n",
    "\n",
    "Nodes: represent customers, financial products\n",
    "\n",
    "Edges: represent relationships or interactions between nodes, such as purchase transactions, \n",
    "\n",
    "Node Features: Customer demographics, purchase history, preferences, etc.\n",
    "\n",
    "Edge Features: Transaction amounts, frequency of interactions, etc.\n",
    "\n",
    "In previous noteboos of this repo (STEP 1), the graph was persisted in graphml format \n",
    "\n",
    "## Feature Engineering:\n",
    "\n",
    "Utilize both node features and edge features to enrich the graph representation.\n",
    "Apply normalization and encoding techniques to prepare the data for GNN processing.\n",
    "\n",
    "\n",
    "## GNN Model Training:\n",
    "\n",
    "Train a GNN to learn embeddings for nodes that capture both the node features and the graph structure.\n",
    "Use these embeddings for clustering customers into segments.\n",
    "\n",
    "## Clustering:\n",
    "\n",
    "Apply clustering algorithms  on the learned node embeddings to identify distinct market segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Load the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "G = nx.read_graphml(\"graph.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Enginnering\n",
    "\n",
    "As I allready have precomputed embeddings from Node2Vec, I will include these embeddings as additional features in my  GNN model. This approach leverages the structural information captured by Node2Vec and combines it with the GNN's ability to learn from node features and graph topology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x (Node Features):\n",
    "\n",
    "x is a matrix where each row corresponds to the feature vector of a node in the graph.\n",
    "The shape of x is [num_nodes, num_node_features].\n",
    "edge_index (Edge Index):\n",
    "\n",
    "edge_index is a tensor that represents the edges of the graph.\n",
    "It is a 2D tensor of shape [2, num_edges], where each column represents an edge. The first row contains the source nodes, and the second row contains the target nodes.\n",
    "edge_attr (Edge Features):\n",
    "\n",
    "edge_attr is an optional tensor that contains the features of the edges.\n",
    "The shape of edge_attr is [num_edges, num_edge_features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2442, -0.1772, -0.2115,  ..., -0.2907, -0.1227, -0.1797])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "# Load embeddings from file c reated by node2vec\n",
    "embeddings = KeyedVectors.load(\"node2vec_embeddings.kv\")\n",
    "\n",
    "\n",
    "# Extract node IDs and features\n",
    "node_ids = []\n",
    "node_types = []\n",
    "\n",
    "for node in G.nodes(data=True):\n",
    "    node_ids.append(str(node[0]))  \n",
    "    node_types.append(node[1]['Node_Type'])\n",
    "\n",
    "node2vec_embeddings = np.array([embeddings[node] for node in node_ids])\n",
    "\n",
    "# One-hot encode the categorical node features\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "node_types_encoded = encoder.fit_transform(np.array(node_types).reshape(-1, 1))\n",
    "\n",
    "# Create tensor node_features with node2vec embeddings and one-hot encoded node types\n",
    "node_features = np.hstack([node2vec_embeddings, node_types_encoded])\n",
    "node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "node_features\n",
    "\n",
    "# Step 3: Create edge index and edge features\n",
    "# Extract node IDs and create a mapping to integer indices\n",
    "node_ids = list(G.nodes())\n",
    "node_id_map = {node_id: i for i, node_id in enumerate(node_ids)}\n",
    "\n",
    "edge_index = []\n",
    "edge_features = []\n",
    "\n",
    "for edge in G.edges(data=True):\n",
    "    source, target = edge[0], edge[1]\n",
    "    edge_index.append([node_id_map[source], node_id_map[target]])\n",
    "    edge_features.append([edge[2]['Frequency'], edge[2]['Total_Amount'], edge[2]['Average_Amount']])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Normalize edge features before creating tensor because they have different scales\n",
    "edge_features = np.array(edge_features)\n",
    "scaler = StandardScaler()\n",
    "edge_features_normalized = scaler.fit_transform(edge_features)\n",
    "# Calculate the average of the normalized frequency and total_amount\n",
    "edge_weights = np.mean(edge_features_normalized[:, :2], axis=1)  # Averaging frequency and total_amount\n",
    "edge_features_normalized = torch.tensor(edge_features_normalized, dtype=torch.float)\n",
    "\n",
    "# Ensure there are no NaN values in edge weights\n",
    "edge_weights = np.nan_to_num(edge_weights)\n",
    "# Convert to tensor\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "\n",
    "# Check for NaNs in node features\n",
    "if torch.isnan(node_features).any():\n",
    "    print(\"NaN values found in node features\")\n",
    "if torch.isnan(edge_weights).any():\n",
    "    print(\"NaN values found in edge weights\")\n",
    "# Data object with node features, edge index and edge features\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features_normalized, edge_weight=edge_weights)\n",
    "#It is not necessary to normalize the node features as  the embeddings are already normalized. =torch.float)  # Apply normalization back\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "loader = NeighborLoader(data, num_neighbors=[15, 10], batch_size=1024, shuffle=True)\n",
    "\n",
    "data\n",
    "edge_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define reconstruction_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def reconstruction_loss(adj_pred, edge_index, num_nodes):\n",
    "    # Create the actual adjacency matrix\n",
    "    adj_true = torch.zeros((num_nodes, num_nodes), device=adj_pred.device)\n",
    "    adj_true[edge_index[0], edge_index[1]] = 1.0\n",
    "\n",
    "    # Compute the reconstruction loss\n",
    "    loss = F.binary_cross_entropy(adj_pred.view(-1), adj_true.view(-1))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([1073296])) that is different to the input size (torch.Size([15])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     48\u001b[0m adj_pred \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m---> 49\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruction_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[97], line 11\u001b[0m, in \u001b[0;36mreconstruction_loss\u001b[1;34m(adj_pred, edge_index, num_nodes)\u001b[0m\n\u001b[0;32m      8\u001b[0m adj_true[edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compute the reconstruction loss\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\Eduardo Toledo\\ASAI\\graph_customer_segmentation\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3145\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3143\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3148\u001b[0m     )\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([1073296])) that is different to the input size (torch.Size([15])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def encode(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        row, col = edge_index\n",
    "        return torch.sigmoid((z[row] * z[col]).sum(dim=1))\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encode(data)\n",
    "        adj_pred = self.decode(z, data.edge_index)\n",
    "        return adj_pred\n",
    "    \n",
    "# Define the input, hidden and output dimensions\n",
    "input_dim = node_features.shape[1]  # The number of features per node\n",
    "hidden_dim = 128  # Number of hidden units in the first GCN layer\n",
    "output_dim = 64  # Number of output units in the second GCN layer\n",
    "\n",
    "# Create the model\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Generate pairs\n",
    "num_nodes = node_features.shape[0]\n",
    "\n",
    "# Training the GNN model\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_values = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        adj_pred = model(batch)\n",
    "        loss = reconstruction_loss(adj_pred, batch.edge_index, batch.num_nodes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
